{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FNqVPqZor8O"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gamma\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8z8XncOB42tx"
   },
   "outputs": [],
   "source": [
    "import c3aidatalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns datetime object of the given date string\n",
    "# Compare dates with >, <, or ==\n",
    "def timeFormat(s):\n",
    "    if str(s) == \"nan\":\n",
    "        return s\n",
    "    else:\n",
    "        return datetime.strptime(s, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# Returns float timestamp (seconds since 1 Jan 1970)\n",
    "# Compare timestamps with >, <, or ==\n",
    "def timestampFormat(s):\n",
    "    if str(s) == \"nan\":\n",
    "        return s\n",
    "    else:\n",
    "        return timeFormat(s).timestamp()\n",
    "\n",
    "# How to convert column of date strings to these above formats:\n",
    "# DFtimeFormat(dataframe name, string of column header which contains the time strings)\n",
    "def DFtimeFormat(df, column_of_timestrings):\n",
    "    df[column_of_timestrings] = df[column_of_timestrings].apply(timeFormat)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dy6zIMzOS_bR"
   },
   "outputs": [],
   "source": [
    "# fetching state policies\n",
    "statePolicies = c3aidatalake.fetch(\n",
    "    \"locationpolicysummary\", \n",
    "    {\n",
    "        \"spec\" : {\n",
    "            \"limit\" : -1\n",
    "        }\n",
    "    }).drop(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilwd4NZ3UiZF"
   },
   "source": [
    "Generating numerical columns from statePolicies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMR1jSGRUz4w"
   },
   "outputs": [],
   "source": [
    "# dicts used to quantify governemnt policy by restrictiveness \n",
    "# (0 - not restrictive -> higher - more restrictive)\n",
    "quantifyDicts = {}\n",
    "quantifyDicts[\"easingOrder\"] = {\n",
    "    \"Reopened\" : 0, \n",
    "    \"Proceeding with Reopening\" : 1,\n",
    "    \"Paused\" : 2, \n",
    "    \"New Restrictions Imposed\" : 3\n",
    "}\n",
    "quantifyDicts[\"stayAtHome\"] = {\n",
    "    \"No Action\" : 0,\n",
    "    \"Lifted\" : 0,\n",
    "    \"Rolled Back to High Risk Groups\" : 1,\n",
    "    \"New Stay at Home Order\" : 2,\n",
    "    \"Statewide\" : 2\n",
    "}\n",
    "quantifyDicts[\"mandatoryQuarantine\"]  = {\n",
    "    \"No Action\" : 0,\n",
    "    \"Lifted\" : 0,\n",
    "    \"From Certain States (New)\" : 1,\n",
    "    \"Rolled Back to Certain States\" : 1,\n",
    "    \"From Certain States\" : 1,\n",
    "    \"Rolled Back to International Travel\" : 2,\n",
    "    \"All Travelers\" : 3\n",
    "}\n",
    "quantifyDicts[\"nonEssentialBusiness\"] = {\n",
    "    \"No Action\" : 0,\n",
    "    \"All Non-Essential Businesses Permitted to Reopen\" : 0,\n",
    "    \"Some Non-Essential Businesses Permitted to Reopen\" : 1,\n",
    "    \"All Non-Essential Businesses Permitted to Reopen with Reduced Capacity\" : 1,\n",
    "    \"Some Non-Essential Businesses Permitted to Reopen with Reduced Capacity\" : 2,\n",
    "    \"New Business Closures or Limits\" : 3\n",
    "}\n",
    "quantifyDicts[\"largeGatherings\"] = {\n",
    "    \"Lifted\" : 0,\n",
    "    \"No Action\" : 0,\n",
    "    \"Expanded to New Limit Above 25\" : 1,\n",
    "    \"New Limit on Large Gatherings in Place\" : 1,\n",
    "    \"Expanded to New Limit of 25 or Fewer\" : 2,\n",
    "    \">10 People Prohibited\" : 3,\n",
    "    \"All Gatherings Prohibited\" : 4\n",
    "}\n",
    "quantifyDicts[\"schoolClosure\"] = {\n",
    "    \"Rescinded\" : 0,\n",
    "    \"Recommended Closure for School Year\" : 1,\n",
    "    \"Recommended Closure\" : 2,\n",
    "    \"Closed for School Year\" : 3,\n",
    "    \"Closed\" : 4\n",
    "}\n",
    "quantifyDicts[\"restaurantLimit\"] = {\n",
    "    \"No Action\" : 0,\n",
    "    \"Reopened to Dine-in Service\" : 1,\n",
    "    \"Reopened to Dine-in Service with Capacity Limits\" : 2,\n",
    "    \"New Service Limits\" : 3,\n",
    "    \"Newly Closed to Dine-in Service\" : 3\n",
    "}\n",
    "quantifyDicts[\"barClosures\"] = {\n",
    "    \"Reopened\" : 0,\n",
    "    \"New Service Limits\" : 1,\n",
    "    \"Closed\" : 2,\n",
    "    \"Newly Closed\" : 2\n",
    "}\n",
    "quantifyDicts[\"faceCoveringRequirement\"] = {\n",
    "    \"No\" : 0,\n",
    "    \"Required for Certain Employees\" : 1,\n",
    "    \"Allows Local Officals to Require for General Public\" : 1,\n",
    "    \"Required for Certain Employees; Allows Local Officials to Require for General Public\" : 1,\n",
    "    \"Required for General Public\" : 2\n",
    "}\n",
    "quantifyDicts[\"PrimaryElectionPostponement\"] = {\n",
    "    \"No\" : 0,\n",
    "    \"Postponed\" : 1,\n",
    "    \"Canceled\" : 2\n",
    "}\n",
    "quantifyDicts[\"emergencyDeclaration\"] = {\n",
    "    \"Yes\" : 0\n",
    "}\n",
    "quantifyDicts[\"waiveTreatmentCost\"]  = {\n",
    "    \"No Action\" : 0,\n",
    "    \"State-Insurer Agreement\" : 1,\n",
    "    \"State Requires\" : 2\n",
    "}  \n",
    "quantifyDicts[\"freeVaccine\"] = {\n",
    "    \"No Action\" : 0,\n",
    "    \"State-Insurer Agreement\" : 1,\n",
    "    \"State Requires\" : 2\n",
    "}\n",
    "quantifyDicts[\"waiverOfPriorAuthorizationRequirements\"] = {\n",
    "    \"No Action\" : 0,\n",
    "    \"For COVID-19 Testing\" : 1,\n",
    "    \"For COVID-19 Testing and Treatment\" : 2\n",
    "}\n",
    "quantifyDicts[\"prescriptionRefill\"] = {\n",
    "    \"No Action\" : 0,\n",
    "    \"Expired\" : 1,\n",
    "    \"State Requires\" : 2\n",
    "}\n",
    "quantifyDicts[\"premiumPaymentGracePeriod\"] = {\n",
    "    \"No Action\" : 0,\n",
    "    \"Expired\" : 1,\n",
    "    \"COVID-19 Diagnosis/Impacts Only\" : 2,\n",
    "    \"Grace Period Extended for All Individual Policies\" : 3,\n",
    "    \"All Policies\" : 4\n",
    "}\n",
    "quantifyDicts[\"marketplaceSpecialEnrollmentPeriod\"] = {\n",
    "    \"No\" : 0,\n",
    "    \"Ended\" : 1,\n",
    "    \"Active\" : 2\n",
    "}\n",
    "quantifyDicts[\"section1135Waiver\"] = {\n",
    "    \"Unapproved\" : 0,\n",
    "    \"Approved\" : 1\n",
    "}\n",
    "quantifyDicts[\"paidSickLeaves\"] = {\n",
    "    \"No Action\" : 0,\n",
    "    \"Proposed - March 2020\" : 1,\n",
    "    \"Enacted\" : 2\n",
    "}\n",
    "quantifyDicts[\"expandsAccesstoTelehealthServices\"] = {\n",
    "    \"No\" : 0,\n",
    "    \"Yes\" : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S64Eg_rJ3l0R"
   },
   "outputs": [],
   "source": [
    "# generates mapper for each column using dicts defined above\n",
    "def mapperGenerator(colName):\n",
    "    if colName in quantifyDicts.keys():\n",
    "        def mapper(val):\n",
    "            return quantifyDicts[colName][val]\n",
    "    else:\n",
    "        def mapper(val):\n",
    "            return val\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in stategdp info\n",
    "# adding quarter 2 gdp change as a column to statepolicies\n",
    "import re\n",
    "stategdp = pd.read_excel(io = \"qgdpstate1020_0.xlsx\", index_col = 0, header = 1)\n",
    "Q2GDPChange = []\n",
    "for id in statePolicies[\"id\"]:\n",
    "    m = re.match(r\"(.+)_UnitedStates_Policy$\", id)\n",
    "    Q2GDPChange.append(stategdp[\"2020Q2\"][m[1]])\n",
    "statePolicies.insert(len(statePolicies.columns), \"Q2GDPChange\", Q2GDPChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting state policies time stamps\n",
    "DFtimeFormat(statePolicies, \"lastSavedTimestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2END is comparison datetime object to find policies implemented before end of 2nd quarter\n",
    "Q2END = datetime(2020, 7, 1)\n",
    "# columns to be used in relevantPolicies\n",
    "newColumns = ['id', 'easingOrder', 'stayAtHome', 'mandatoryQuarantine', 'nonEssentialBusiness', 'largeGatherings', \n",
    "              'schoolClosure', 'restaurantLimit', 'barClosures', 'faceCoveringRequirement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns are newColumns + versionDate + Q2GDPChange\n",
    "# create new data frame\n",
    "# for each state in statePolicies, try to access relevant dates, or use info from statePolicies\n",
    "# append to data frame\n",
    "relevantPolicies = []\n",
    "for i in statePolicies.index:\n",
    "    data = []\n",
    "    try:\n",
    "        allStateVersions = c3aidatalake.read_data_json(\n",
    "            \"locationpolicysummary\",\n",
    "            \"allversionsforpolicy\",\n",
    "            body = {\n",
    "                \"this\" : {\n",
    "                    \"id\" : statePolicies[\"id\"][i]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        allStateVersions = pd.json_normalize(allStateVersions)\n",
    "        DFtimeFormat(allStateVersions, \"versionDate\")\n",
    "        relevantPolicyFound = False\n",
    "        for ind in allStateVersions.index:\n",
    "            if allStateVersions[\"versionDate\"][ind] < Q2END:\n",
    "                data = [allStateVersions[col][ind] for col in newColumns]\n",
    "                data.append(allStateVersions[\"versionDate\"][ind])\n",
    "                relevantPolicyFound = True\n",
    "                break\n",
    "        if not relevantPolicyFound:\n",
    "            raise \n",
    "    except:\n",
    "        data = [statePolicies[col][i] for col in newColumns]\n",
    "        data.append(statePolicies[\"lastSavedTimestamp\"][i])\n",
    "    data.append(statePolicies[\"Q2GDPChange\"][i])\n",
    "    relevantPolicies.append(data)\n",
    "relevantPolicies = pd.DataFrame(relevantPolicies, columns = newColumns + [\"versionDate\", \"Q2GDPChange\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables for multiple linear regression\n",
    "xVars = ['easingOrder', 'stayAtHome', 'mandatoryQuarantine', 'nonEssentialBusiness', 'largeGatherings', \n",
    "         'schoolClosure', 'restaurantLimit', 'barClosures', 'faceCoveringRequirement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantify relevantPolicies\n",
    "for col in relevantPolicies.columns:\n",
    "    mper = mapperGenerator(col)\n",
    "    relevantPolicies[col] = relevantPolicies[col].apply(mper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantX = relevantPolicies[xVars]\n",
    "relevantY = relevantPolicies[\"Q2GDPChange\"]\n",
    "relevantRegr = linear_model.LinearRegression()\n",
    "relevantRegr.fit(relevantX, relevantY)\n",
    "for i in range(len(xVars)):\n",
    "    print(\"Coefficient of \", xVars[i], \": \", relevantRegr.coef_[i])\n",
    "print(\"Intercept: \", relevantRegr.intercept_)\n",
    "print(\"R^2: \", relevantRegr.score(relevantX, relevantY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression for feature importance\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, y = relevantX, relevantY\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree for feature importance on a regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, y = relevantX, relevantY\n",
    "# define the model\n",
    "model = DecisionTreeRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for feature importance on a regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, y = relevantX, relevantY\n",
    "# define the model\n",
    "model = RandomForestRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation feature importance with knn for regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, y = relevantX, relevantY\n",
    "# define the model\n",
    "model = KNeighborsRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# perform permutation importance\n",
    "results = permutation_importance(model, X, y, scoring='neg_mean_squared_error')\n",
    "# get importance\n",
    "importance = results.importances_mean\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add up quantified policies to get aggregate measure of restrictiveness\n",
    "def addRestrictMeasure(df, varsToUse):\n",
    "    sums = [sum([df[var][i] for var in varsToUse]) for i in df.index]\n",
    "    df.insert(loc = len(df.columns), column = \"restrictivenessMeasure\", value = sums)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addRestrictMeasure(relevantPolicies, xVars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running regression of change in gdp on restrictivnessMeasure\n",
    "relAggrRegr = linear_model.LinearRegression()\n",
    "relRestrMeas = relevantPolicies[[\"restrictivenessMeasure\"]]\n",
    "Y = statePolicies[\"Q2GDPChange\"]\n",
    "relAggrRegr.fit(relRestrMeas, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficient of restrictivenessMeasure: \", relAggrRegr.coef_[0])\n",
    "print(\"Intercept: \", relAggrRegr.intercept_)\n",
    "print(\"R^2: \", relAggrRegr.score(relRestrMeas, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(relevantPolicies[\"restrictivenessMeasure\"], relevantPolicies[\"Q2GDPChange\"])\n",
    "minRestric = min(relevantPolicies[\"restrictivenessMeasure\"])\n",
    "maxRestric = max(relevantPolicies[\"restrictivenessMeasure\"])\n",
    "xCords = np.linspace(minRestric, maxRestric)\n",
    "yCords = xCords * relAggrRegr.coef_[0] + relAggrRegr.intercept_\n",
    "plt.plot(xCords, yCords)\n",
    "plt.xlabel(\"Sum of Restrictiveness Policies\")\n",
    "plt.ylabel(\"Change in GDP in Q2 of 2020\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sora_Rithwik_Tyler.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
